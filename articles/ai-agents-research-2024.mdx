---
title: "Jack Hales AI Agents Research Journal - 2024"
description: "AI Agent thoughts and research from Jack Hales within 2024."
date: "17 November 2024"
---

**Preface:** I want to define the minimum high-impact activities an agent can do within my workflow. Then, I want to evaluate the potential benefits of creating a permanent runtime, rather than a temporary "invoked" runtime.

### What is an AI Agent?

My conception of an AI Agent is something that runs in a temporary "invoked" runtime, or a permanent runtime, within a specific structure of a LLM-model. It involves inputs, as well as an attempt to coerce to a model-decided output, and an output parser to run certain actions based on the models output.

The inputs conventionally involve a mix of a chaotic user-request, as well as common instructions for how to respond. Something like: 

> "You will respond to user input. You will return output in JSON. Your options are ---. The users input is: ---."

With a bit more rigidity - but the basic idea is encapsulated above.

### Is an AI Agent necessary?

This is an important aspect to review, before jumping into AI Agent world. To help, I will start with what I commonly do at work, as well as some unusual exceptions.

- **Programming:** I am often taking ideas, and converting them into the code which is required to run those features.
- **Emails:** I read and respond to a plethora of emails - some business-important, some functional, some documentative.

### What LLMs are natively great for

LLMs are great at parsing text, and has basically surplanted classical machine learning categorisation tasks completely. I'd summise that LLMs are great at "in-the-box" thinking, or potentially working with defined problem spaces. Say I ask a model to generate something superwild, and turn the temperature up, then put that into an "in-the-box" model - this might mimic some form of cross-domain creativity which humans often work within. But, this is just hand-waving I'm afraid - I will continue looking.

Ask an LLM to tell you what you can make with ingredients. With current models, it will do phenomenally with existing recipies that exist - but not recommend anything unseen - this is expected.

Ask an LLM to help you refactor some code - it will use well-known existing patterns. But, it will not stake it's career on some "thought" it had regarding a potentially better, unseen pattern, which could be tested and improve the system tenfold.

Ask an LLM to rank an idea - it will help you confirm it's plausability, and factor away potential risks to a point where you can take the leap - potentially devestatingly.

(PLEASE NOTE: I am writing a lot of fluff. The above are just ideas I am putting down. To be revised!)
